# core/archive_manager.py
import mysql.connector
from config.settings import settings
import logging
import re

class ArchiveManager:
    def __init__(self):
        """åˆå§‹åŒ–æ¡£æ¡ˆç®¡ç†å™¨"""
        self.logger = logging.getLogger("archive_manager")
        self.connection = None
        self.connect()

    def connect(self):
        """è¿æ¥åˆ°MySQLæ•°æ®åº“"""
        try:
            self.connection = mysql.connector.connect(
                host=settings.database_config['host'],
                port=settings.database_config['port'],
                user=settings.database_config['user'],
                password=settings.database_config['password'],
                database=settings.database_config['database']
            )
            self.logger.info("âœ… MySQLæ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False

    def query_archive(self, query_text):
        """æŸ¥è¯¢æ¡£æ¡ˆ - ç»Ÿä¸€æŸ¥è¯¢æ‰€æœ‰ç›¸å…³å­—æ®µ"""
        try:
            self.logger.info(f"æ¡£æ¡ˆæŸ¥è¯¢: {query_text}")

            # æ¸…ç†æŸ¥è¯¢æ–‡æœ¬
            query_value = self._clean_query_text(query_text)

            if not query_value:
                return {
                    'success': False,
                    'error': 'è¯·æä¾›æ¡£æ¡ˆåç§°æˆ–ç¼–å·è¿›è¡ŒæŸ¥è¯¢',
                    'results': []
                }

            # æ‰§è¡ŒæŸ¥è¯¢
            if self.connection and self.connection.is_connected():
                return self._execute_double_query(query_value)
            else:
                return {
                    'success': False,
                    'error': 'æ•°æ®åº“è¿æ¥å¤±è´¥',
                    'results': []
                }

        except Exception as e:
            self.logger.error(f"æ¡£æ¡ˆæŸ¥è¯¢å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'results': []
            }

    def _clean_query_text(self, text):
        """æ¸…ç†æŸ¥è¯¢æ–‡æœ¬ - ç§»é™¤å¸¸è§çš„å‰ç¼€å’Œåç¼€ï¼Œå¹¶æå–å…³é”®ä¿¡æ¯"""
        text = text.strip()

        # æ¸…ç†æŸ¥è¯¢å‰ç¼€
        query_prefixes = [
            'å¸®æˆ‘æŸ¥è¯¢', 'å¸®æˆ‘æŸ¥ä¸€ä¸‹', 'å¸®æˆ‘æ‰¾ä¸€ä¸‹', 'å¸®æˆ‘æœç´¢',
            'æŸ¥è¯¢', 'æŸ¥ä¸€ä¸‹', 'æŸ¥æ‰¾', 'æ‰¾ä¸€ä¸‹', 'æœç´¢',
            'æŸ¥æŸ¥', 'æŸ¥', 'æ‰¾', 'æœ'
        ]

        for prefix in query_prefixes:
            if text.startswith(prefix):
                text = text[len(prefix):].strip()
                break

        # æ¸…ç†æŸ¥è¯¢åç¼€
        query_suffixes = ['çš„æ¡£æ¡ˆ', 'æ¡£æ¡ˆ', 'çš„èµ„æ–™', 'çš„ä¿¡æ¯']
        for suffix in query_suffixes:
            if text.endswith(suffix):
                text = text[:-len(suffix)].strip()
                break

        # ç‰¹åˆ«å¤„ç†"ä¸º"å’Œ"æ˜¯"è¿æ¥çš„æƒ…å†µï¼Œå¦‚"æ¥çº¿æ–¹å¼ä¸ºä¸‰ç›¸ä¸‰çº¿"
        # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ï¼šXXXä¸ºYYY æˆ– XXXæ˜¯YYY çš„å½¢å¼
        pattern = r'(.+?)(?:ä¸º|æ˜¯)(.+)$'
        match = re.match(pattern, text)

        if match:
            # è·å–å…³é”®å­—å‰çš„æè¿°éƒ¨åˆ†ï¼ˆå¦‚"æ¥çº¿æ–¹å¼"ï¼‰å’Œå®é™…å€¼ï¼ˆå¦‚"ä¸‰ç›¸ä¸‰çº¿"ï¼‰
            description = match.group(1).strip()
            actual_value = match.group(2).strip()

            self.logger.info(f"ğŸ“ æ£€æµ‹åˆ°æè¿°æ€§æŸ¥è¯¢: '{description}' ä¸º/æ˜¯ '{actual_value}'")

            # å¦‚æœæè¿°åŒ…å«"æ¥çº¿æ–¹å¼"ï¼Œæˆ‘ä»¬åªæå–å®é™…å€¼
            if 'æ¥çº¿æ–¹å¼' in description:
                text = actual_value
                self.logger.info(f"ğŸ“ æå–æ¥çº¿æ–¹å¼å€¼: '{text}'")
            else:
                # å…¶ä»–æƒ…å†µï¼Œä¹Ÿä½¿ç”¨å®é™…å€¼
                text = actual_value

        return text

    def _execute_double_query(self, query_value):
        """æ‰§è¡ŒåŒé‡æŸ¥è¯¢ - å…ˆæŸ¥è¯¢è½¬æ¢åçš„é˜¿æ‹‰ä¼¯æ•°å­—ï¼Œå†æŸ¥è¯¢åŸå§‹ä¸­æ–‡æ•°å­—"""
        try:
            cursor = self.connection.cursor(dictionary=True)

            # ä¸­æ–‡æ•°å­—åˆ°é˜¿æ‹‰ä¼¯æ•°å­—çš„æ˜ å°„
            chinese_number_map = {
                'é›¶': '0', 'ä¸€': '1', 'äºŒ': '2', 'ä¸¤': '2', 'ä¸‰': '3', 'å››': '4',
                'äº”': '5', 'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9', 'å': '10',
                'åä¸€': '11', 'åäºŒ': '12', 'åä¸‰': '13', 'åå››': '14', 'åäº”': '15',
                'åå…­': '16', 'åä¸ƒ': '17', 'åå…«': '18', 'åä¹': '19', 'äºŒå': '20',
                'äºŒåä¸€': '21', 'äºŒåäºŒ': '22', 'äºŒåä¸‰': '23', 'äºŒåå››': '24', 'äºŒåäº”': '25',
                'äºŒåå…­': '26', 'äºŒåä¸ƒ': '27', 'äºŒåå…«': '28', 'äºŒåä¹': '29', 'ä¸‰å': '30'
            }

            # è½¬æ¢ä¸­æ–‡æ•°å­—åˆ°é˜¿æ‹‰ä¼¯æ•°å­—
            converted_value = query_value
            for chinese, arabic in chinese_number_map.items():
                if chinese in query_value:
                    converted_value = converted_value.replace(chinese, arabic)

            print(f"ğŸ“ [DEBUG] æŸ¥è¯¢å€¼è½¬æ¢: '{query_value}' -> '{converted_value}'")

            # å®šä¹‰æŸ¥è¯¢å‡½æ•°ï¼Œç”¨äºæ‰§è¡Œå•æ¬¡æŸ¥è¯¢
            def execute_single_query(search_value):
                query = """
                    SELECT DISTINCT ta.*
                    FROM `t_archives` ta
                    LEFT JOIN t_archives_attachment taa ON ta.id = taa.archives_id
                    WHERE ta.is_del = '0'
                    AND (
                        -- æ¡£æ¡ˆè¡¨å­—æ®µ
                        ta.title LIKE CONCAT('%', %s, '%')
                        OR ta.dang_num LIKE CONCAT('%', %s, '%')
                    )
                    ORDER BY ta.create_time DESC
                """
                # å‚æ•°æ•°é‡å’Œå ä½ç¬¦æ•°é‡å¿…é¡»ä¸€è‡´ï¼š2ä¸ªå ä½ç¬¦ï¼Œ2ä¸ªå‚æ•°
                cursor.execute(query, (search_value, search_value))
                return cursor.fetchall()

            # ç¬¬ä¸€æ¬¡æŸ¥è¯¢ï¼šä½¿ç”¨è½¬æ¢åçš„é˜¿æ‹‰ä¼¯æ•°å­—
            results1 = execute_single_query(converted_value)
            print(f"ğŸ“Š [DEBUG] ç¬¬ä¸€æ¬¡æŸ¥è¯¢ç»“æœæ•°é‡: {len(results1)}")

            # ç¬¬äºŒæ¬¡æŸ¥è¯¢ï¼šä½¿ç”¨åŸå§‹ä¸­æ–‡æ•°å­—
            results2 = execute_single_query(query_value)

            # åˆå¹¶ä¸¤æ¬¡æŸ¥è¯¢ç»“æœå¹¶å»é‡
            all_results = results1 + results2

            # å»é‡ï¼ˆæŒ‰æ ‡é¢˜å’Œç¼–å·ï¼‰
            unique_results = []
            seen_keys = set()

            for result in all_results:
                key = f"{result.get('title', '')}_{result.get('dang_num', '')}"
                if key not in seen_keys:
                    seen_keys.add(key)
                    unique_results.append(result)

            print(f"ğŸ“Š [DEBUG] å»é‡åç»“æœæ•°é‡: {len(unique_results)}")

            # å¦‚æœåŒé‡æŸ¥è¯¢æ²¡æœ‰ç»“æœï¼Œåˆ™å°è¯•é€šè¿‡æ–‡æ¡£æŸ¥è¯¢æ¥å£æŸ¥æ‰¾
            if len(unique_results) == 0:
                print(f"ğŸ” [DEBUG] åŒé‡æŸ¥è¯¢æ— ç»“æœï¼Œå°è¯•é€šè¿‡æ–‡æ¡£æŸ¥è¯¢æ¥å£æŸ¥æ‰¾: '{query_value}'")
                try:
                    # å°è¯•å¯¼å…¥ä¸»åº”ç”¨ä¸­çš„æ–‡æ¡£æŸ¥è¯¢å‡½æ•°
                    import requests
                    import json

                    # æ„å»ºè¯·æ±‚å‚æ•°
                    request_data = {'query_text': query_value}
                    print(f"ğŸ“¤ [DEBUG] å‘é€æ–‡æ¡£æŸ¥è¯¢è¯·æ±‚å‚æ•°: {json.dumps(request_data, ensure_ascii=False)}")

                    # è°ƒç”¨æ–‡æ¡£æŸ¥è¯¢æ¥å£
                    response = requests.post(
                        'http://localhost:5000/api/documents/query',
                        json=request_data,
                        timeout=10
                    )

                    print(f"ğŸ“¥ [DEBUG] æ–‡æ¡£æŸ¥è¯¢æ¥å£å“åº”çŠ¶æ€ç : {response.status_code}")

                    if response.status_code == 200:
                        data = response.json()
                        print(f"ğŸ“¥ [DEBUG] æ–‡æ¡£æŸ¥è¯¢æ¥å£è¿”å›åŸå§‹æ•°æ®: {json.dumps(data, ensure_ascii=False)}")

                        if data.get('success') and data.get('documents'):
                            documents = data.get('documents', [])
                            print(f"ğŸ“„ [DEBUG] æ–‡æ¡£æŸ¥è¯¢æ¥å£è§£æåè¿”å› {len(documents)} ä¸ªæ–‡æ¡£: {documents}")

                            # å¯¹æ¯ä¸ªæ–‡æ¡£åè¿›è¡ŒæŸ¥è¯¢
                            document_results = []
                            for doc_name in documents:
                                # æ¸…ç†æ–‡æ¡£å
                                import re
                                # ç§»é™¤ "æ•°å­—. " æ ¼å¼çš„å‰ç¼€
                                doc_name_clean = re.sub(r'^\d+\.\s*', '', doc_name)
                                # ç§»é™¤æ‹¬å·åŠæ‹¬å·å†…çš„å†…å®¹ï¼ˆå¦‚"(æ¿€å…‰ç†”è¦†)"ï¼‰
                                doc_name_clean = re.sub(r'\([^)]*\)', '', doc_name_clean)
                                # ç§»é™¤æ–‡ä»¶æ‰©å±•å
                                doc_name_without_ext = doc_name_clean.split('.')[0] if '.' in doc_name_clean else doc_name_clean
                                # ç§»é™¤å‰åç©ºæ ¼
                                doc_name_without_ext = doc_name_without_ext.strip()

                                print(f"ğŸ” [DEBUG] åŸå§‹æ–‡æ¡£å: '{doc_name}'")

                                # æŸ¥è¯¢æ¡£æ¡ˆè¡¨ï¼ˆä½¿ç”¨nameå­—æ®µï¼‰
                                name_query = """
                                    SELECT DISTINCT ta.*
                                    FROM `t_archives` ta
                                    LEFT JOIN t_archives_attachment taa ON ta.id = taa.archives_id
                                    WHERE ta.is_del = '0'
                                    AND taa.name LIKE CONCAT('%', %s, '%')
                                    ORDER BY ta.create_time DESC
                                """
                                cursor.execute(name_query, (doc_name_without_ext,))
                                doc_results = cursor.fetchall()

                                if doc_results:
                                    print(f"ğŸ” [DEBUG] æ ¹æ®æ–‡æ¡£å '{doc_name_without_ext}' æŸ¥è¯¢åˆ° {len(doc_results)} æ¡æ¡£æ¡ˆè®°å½•")
                                    document_results.extend(doc_results)

                            # å¦‚æœé€šè¿‡æ–‡æ¡£åæŸ¥è¯¢åˆ°ç»“æœï¼Œåˆå¹¶å¹¶å»é‡
                            if document_results:
                                # å»é‡
                                seen_doc_keys = set()
                                unique_doc_results = []

                                for result in document_results:
                                    key = f"{result.get('title', '')}_{result.get('dang_num', '')}"
                                    if key not in seen_doc_keys:
                                        seen_doc_keys.add(key)
                                        unique_doc_results.append(result)

                                print(f"ğŸ“Š [DEBUG] æ–‡æ¡£æŸ¥è¯¢æœ€ç»ˆå»é‡åç»“æœæ•°é‡: {len(unique_doc_results)}")

                                # è¿”å›æ–‡æ¡£æŸ¥è¯¢çš„ç»“æœ - ä¿æŒä¸SQLæŸ¥è¯¢å®Œå…¨ä¸€è‡´çš„ç»“æ„
                                cursor.close()
                                return {
                                    'success': True,
                                    'query_value': query_value,
                                    'converted_value': converted_value,
                                    'results': unique_doc_results,
                                    'count': len(unique_doc_results),
                                    'query_type': 'double'  # ä¿æŒä¸€è‡´çš„æŸ¥è¯¢ç±»å‹
                                }
                            else:
                                print("âŒ [DEBUG] æ–‡æ¡£æŸ¥è¯¢æ¥å£è¿”å›æ–‡æ¡£åï¼Œä½†æœªåœ¨æ¡£æ¡ˆè¡¨ä¸­æ‰¾åˆ°å¯¹åº”è®°å½•")
                        else:
                            error_msg = data.get('error', 'æœªçŸ¥é”™è¯¯')
                            print(f"âŒ [DEBUG] æ–‡æ¡£æŸ¥è¯¢æ¥å£è°ƒç”¨å¤±è´¥: {error_msg}")
                    else:
                        response_text = response.text[:500] if response.text else "æ— å“åº”å†…å®¹"
                        print(f"âŒ [DEBUG] æ–‡æ¡£æŸ¥è¯¢æ¥å£HTTPé”™è¯¯: {response.status_code}, å“åº”å†…å®¹: {response_text}")
                except requests.exceptions.Timeout:
                    print("âŒ [DEBUG] è°ƒç”¨æ–‡æ¡£æŸ¥è¯¢æ¥å£è¶…æ—¶")
                except requests.exceptions.ConnectionError:
                    print("âŒ [DEBUG] æ— æ³•è¿æ¥åˆ°æ–‡æ¡£æŸ¥è¯¢æ¥å£ï¼Œè¯·ç¡®ä¿ä¸»åº”ç”¨å·²å¯åŠ¨")
                except json.JSONDecodeError as e:
                    print(f"âŒ [DEBUG] æ–‡æ¡£æŸ¥è¯¢æ¥å£è¿”å›JSONè§£æå¤±è´¥: {e}")
                except Exception as e:
                    print(f"âŒ [DEBUG] è°ƒç”¨æ–‡æ¡£æŸ¥è¯¢æ¥å£å¼‚å¸¸: {e}")
                    import traceback
                    traceback.print_exc()

            cursor.close()

            return {
                'success': True,
                'query_value': query_value,
                'converted_value': converted_value,
                'results': unique_results,
                'count': len(unique_results),
                'query_type': 'double'  # æ ‡è®°ä½¿ç”¨äº†åŒé‡æŸ¥è¯¢
            }

        except Exception as e:
            print(f"âŒ [DEBUG] æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
            if 'cursor' in locals():
                cursor.close()
            return {
                'success': False,
                'error': str(e),
                'results': []
            }
    def format_archive_results(self, archive_result):
        """æ ¼å¼åŒ–æ¡£æ¡ˆæŸ¥è¯¢ç»“æœ"""
        if not archive_result.get('success', False):
            return "æŸ¥è¯¢æ¡£æ¡ˆæ—¶å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åå†è¯•"

        results = archive_result.get('results', [])
        query_value = archive_result.get('query_value', '')
        converted_value = archive_result.get('converted_value', '')

        if not results:
            return f"æ²¡æœ‰æ‰¾åˆ°åŒ…å«'{query_value}'æˆ–'{converted_value}'çš„æ¡£æ¡ˆä¿¡æ¯"

        if len(results) == 1:
            archive = results[0]
            # è¿”å›ç®€æ´çš„æ¡£æ¡ˆä¿¡æ¯ï¼Œå»æ‰è¡¨æƒ…ç¬¦å·å’Œç¼©è¿›
            return f"æ¡£æ¡ˆåç§°ï¼š{archive.get('title', 'æœªçŸ¥')}ï¼Œæ¡£æ¡ˆç¼–å·ï¼š{archive.get('dang_num', 'æœªçŸ¥')}ï¼Œåˆ›å»ºæ—¶é—´ï¼š{archive.get('create_time', 'æœªçŸ¥')}"
        else:
            # è¿”å›å›¾ç‰‡ä¸­çš„æ ¼å¼ï¼š"ä¸ºæ‚¨æ‰¾åˆ°Xæ¡ç›¸å…³æ¡£æ¡ˆï¼Œè¯·é€‰æ‹©è¦æŸ¥çœ‹å“ªä¸€æ¡"
            return f"ä¸ºæ‚¨æ‰¾åˆ°{len(results)}æ¡ç›¸å…³æ¡£æ¡ˆï¼Œè¯·é€‰æ‹©è¦æŸ¥çœ‹å“ªä¸€æ¡"

    def query_attachment_by_archive_id(self, archive_id):
        """æ ¹æ®æ¡£æ¡ˆIDæŸ¥è¯¢é™„ä»¶ä¿¡æ¯"""
        try:
            if not archive_id:
                return {
                    'success': False,
                    'error': 'æ¡£æ¡ˆIDä¸èƒ½ä¸ºç©º',
                    'results': []
                }

            if not self.connection or not self.connection.is_connected():
                # å°è¯•é‡æ–°è¿æ¥
                if not self.connect():
                    return {
                        'success': False,
                        'error': 'æ•°æ®åº“è¿æ¥å¤±è´¥',
                        'results': []
                    }

            cursor = self.connection.cursor(dictionary=True)

            # ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢é˜²æ­¢SQLæ³¨å…¥
            query = """
                SELECT * 
                FROM `t_archives_attachment` 
                WHERE archives_id = %s
                ORDER BY create_time DESC
            """

            cursor.execute(query, (archive_id,))
            results = cursor.fetchall()
            cursor.close()

            self.logger.info(f"æŸ¥è¯¢é™„ä»¶æˆåŠŸï¼Œæ¡£æ¡ˆID: {archive_id}, é™„ä»¶æ•°é‡: {len(results)}")

            return {
                'success': True,
                'archive_id': archive_id,
                'results': results,
                'count': len(results)
            }

        except mysql.connector.Error as e:
            self.logger.error(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
            return {
                'success': False,
                'error': f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {str(e)}",
                'results': []
            }
        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢é™„ä»¶æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return {
                'success': False,
                'error': f"æŸ¥è¯¢é™„ä»¶æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
                'results': []
            }

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.connection and self.connection.is_connected():
            self.connection.close()
            self.logger.info("âœ… æ¡£æ¡ˆç®¡ç†å™¨æ•°æ®åº“è¿æ¥å·²å…³é—­")