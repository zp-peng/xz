# core/voice_recognizer.py
import audioop
import json
import numpy as np
import os
import pyaudio
import random
import re
import time
import vosk
import wave

from utils.logger import setup_logger


class VoiceRecognizer:
    def __init__(self, database_manager=None, command_handler=None):
        self.database_manager = database_manager
        self.command_handler = command_handler
        self.audio = pyaudio.PyAudio()
        self.logger = setup_logger("VoiceRecognizer")

        # æ¨¡å‹é…ç½®
        self.model_path = "model/vosk-model-cn-0.22"
        self.model = None
        self.recognizer = None
        self.system_audio_threshold = 0.8  # ç³»ç»Ÿå£°éŸ³æ£€æµ‹é˜ˆå€¼
        self.last_system_audio_time = 0    # æœ€åæ£€æµ‹åˆ°ç³»ç»Ÿå£°éŸ³çš„æ—¶é—´
        self.system_audio_cooldown = 1.0   # ç³»ç»Ÿå£°éŸ³æ£€æµ‹å†·å´æ—¶é—´

        # éŸ³é¢‘å‚æ•°
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 16000

        # ä½¿ç”¨ä¿å®ˆçš„é»˜è®¤å€¼ï¼Œé¿å…ç«‹å³æ ¡å‡†
        self.silence_threshold = 2.0
        self.silence_duration = 1.2
        self.min_voice_duration = 0.3
        self.gain = 1.5

        # å…¶ä»–çŠ¶æ€å˜é‡
        self.wake_word = "å°æ™º"
        self.wake_word_detected = False
        self._is_cleaning_up = False
        self.ambient_noise_level = 1.5

        # è¯­éŸ³æ’­æ”¾çŠ¶æ€æ§åˆ¶ - å¢å¼ºç‰ˆæœ¬
        self._is_speaking = False
        self._last_speech_end_time = 0
        self._playback_cooldown = 0.5  # æ’­æ”¾ç»“æŸåçŸ­æš‚å†·å´æœŸ
        self._playback_state_listeners = []

        # åŒæ­¥åŠ è½½æ¨¡å‹
        self.model_loaded = False
        self.load_model_sync()  # æ”¹ä¸ºåŒæ­¥åŠ è½½
        self.detect_ambient_noise()
        self.cleanup_temp_files()

    def add_playback_state_listener(self, listener):
        """æ·»åŠ æ’­æ”¾çŠ¶æ€ç›‘å¬å™¨"""
        if listener not in self._playback_state_listeners:
            self._playback_state_listeners.append(listener)

    def remove_playback_state_listener(self, listener):
        """ç§»é™¤æ’­æ”¾çŠ¶æ€ç›‘å¬å™¨"""
        if listener in self._playback_state_listeners:
            self._playback_state_listeners.remove(listener)

    def _notify_playback_state_change(self, is_speaking):
        """é€šçŸ¥æ‰€æœ‰ç›‘å¬å™¨æ’­æ”¾çŠ¶æ€å˜åŒ–"""
        for listener in self._playback_state_listeners:
            try:
                if hasattr(listener, 'on_playback_state_change'):
                    listener.on_playback_state_change(is_speaking)
            except Exception as e:
                self.logger.warning(f"æ’­æ”¾çŠ¶æ€ç›‘å¬å™¨é€šçŸ¥å¤±è´¥: {e}")

    def set_speaking_status(self, is_speaking):
        """è®¾ç½®è¯­éŸ³æ’­æ”¾çŠ¶æ€ - å¢å¼ºç‰ˆæœ¬"""
        old_state = self._is_speaking
        self._is_speaking = is_speaking

        if old_state != is_speaking:
            if is_speaking:
                self.logger.info("ğŸ”Š è¯­éŸ³æ’­æ”¾å¼€å§‹ï¼Œæš‚åœè¯­éŸ³ç›‘å¬")
            else:
                self._last_speech_end_time = time.time()
                self.logger.info("ğŸ”‡ è¯­éŸ³æ’­æ”¾ç»“æŸï¼Œå‡†å¤‡æ¢å¤è¯­éŸ³ç›‘å¬")

            # é€šçŸ¥çŠ¶æ€å˜åŒ–
            self._notify_playback_state_change(is_speaking)

    def should_ignore_for_playback(self):
        """æ£€æŸ¥æ˜¯å¦å› æ’­æ”¾çŠ¶æ€è€Œå¿½ç•¥è¯­éŸ³è¯†åˆ« - å¢å¼ºç‰ˆæœ¬"""
        if self._is_speaking:
            return True

        # æ’­æ”¾ç»“æŸåçŸ­æš‚å†·å´æœŸ
        if time.time() - self._last_speech_end_time < self._playback_cooldown:
            return True

        return False

    def is_system_playback_audio(self, audio_data):
        """æ£€æµ‹æ˜¯å¦ä¸ºç³»ç»Ÿè‡ªå·±æ’­æ”¾çš„éŸ³é¢‘ - å¢å¼ºç‰ˆæœ¬"""
        try:
            if audio_data is None or len(audio_data) == 0:
                return False

            # æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…
            current_time = time.time()
            if current_time - self.last_system_audio_time < self.system_audio_cooldown:
                return True

            # è½¬æ¢ä¸ºnumpyæ•°ç»„åˆ†æ
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            if len(audio_array) < 100:
                return False

            # è®¡ç®—éŸ³é¢‘ç‰¹å¾
            rms = np.sqrt(np.mean(np.square(audio_array.astype(np.float64))))
            peak = np.max(np.abs(audio_array))

            # è®¡ç®—è¿‡é›¶ç‡ï¼ˆZero Crossing Rateï¼‰
            zero_crossings = np.sum(np.diff(np.signbit(audio_array)))
            zcr = zero_crossings / len(audio_array)

            # è®¡ç®—é¢‘è°±ç‰¹å¾
            fft_data = np.abs(np.fft.fft(audio_array))
            fft_data = fft_data[:len(fft_data)//2]  # å–å‰åŠéƒ¨åˆ†
            spectral_centroid = np.sum(fft_data * np.arange(len(fft_data))) / np.sum(fft_data)

            # ç³»ç»Ÿæ’­æ”¾å£°éŸ³çš„ç‰¹å¾ï¼ˆé€šå¸¸æ›´å¹³ç¨³ã€é¢‘è°±æ›´é›†ä¸­ï¼‰
            is_system_sound = (
                # éŸ³é‡åœ¨ä¸€å®šèŒƒå›´å†…ï¼ˆä¸æ˜¯ç¯å¢ƒå™ªéŸ³ï¼Œä¹Ÿä¸æ˜¯è¿‡å¤§çš„å£°éŸ³ï¼‰
                    800 < rms < 15000 and
                    # å³°å€¼ä¸ä¼šè¿‡é«˜
                    peak < 25000 and
                    # è¿‡é›¶ç‡è¾ƒä½ï¼ˆå£°éŸ³è¾ƒå¹³ç¨³ï¼‰
                    zcr < 0.2 and
                    # é¢‘è°±ä¸­å¿ƒè¾ƒä½ï¼ˆå£°éŸ³é¢‘ç‡è¾ƒä½ï¼‰
                    spectral_centroid < 1000
            )

            if is_system_sound:
                self.last_system_audio_time = current_time

            return is_system_sound

        except Exception as e:
            self.logger.warning(f"ç³»ç»ŸéŸ³é¢‘æ£€æµ‹å¤±è´¥: {e}")
            return False

    def load_model_sync(self):
        """åŒæ­¥åŠ è½½Voskæ¨¡å‹ - ä¿®å¤ç‰ˆæœ¬"""
        try:
            print(f"ğŸ¯ æ­£åœ¨åŒæ­¥åŠ è½½ Vosk æ¨¡å‹...")

            # æ£€æŸ¥æ¨¡å‹è·¯å¾„
            if not os.path.exists(self.model_path):
                print(f"âŒ Vosk æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {self.model_path}")
                possible_paths = [
                    "model/vosk-model-cn-0.22",
                    "model/vosk-model-small-cn-0.22",
                    "model",
                    "vosk-model-cn-0.22"
                ]
                for path in possible_paths:
                    if os.path.exists(path):
                        print(f"ğŸ” æ‰¾åˆ°å¤‡é€‰è·¯å¾„: {path}")
                        self.model_path = path
                        break
                else:
                    print("âŒ æ‰€æœ‰å¤‡é€‰è·¯å¾„éƒ½ä¸å­˜åœ¨")
                    self.model_loaded = False
                    return False

            # åŠ è½½æ¨¡å‹
            self.model = vosk.Model(self.model_path)
            self.recognizer = vosk.KaldiRecognizer(self.model, self.rate)

            # ç®€å•æµ‹è¯•æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
            test_result = self.recognizer.AcceptWaveform(b'test' * 100)  # æ·»åŠ æµ‹è¯•æ•°æ®
            self.model_loaded = True

            print("âœ… Vosk æ¨¡å‹åŒæ­¥åŠ è½½æˆåŠŸ!")
            return True

        except Exception as e:
            print(f"âŒ Vosk æ¨¡å‹åŒæ­¥åŠ è½½å¤±è´¥: {e}")
            self.model_loaded = False
            return False

    def _ensure_temp_audio_dir(self):
        """ç¡®ä¿ä¸´æ—¶éŸ³é¢‘ç›®å½•å­˜åœ¨"""
        temp_audio_dir = "temp_audio"
        if not os.path.exists(temp_audio_dir):
            os.makedirs(temp_audio_dir, exist_ok=True)
        return temp_audio_dir

    def _get_temp_audio_path(self):
        """è·å–ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨é¡¹ç›®temp_audioç›®å½•"""
        temp_audio_dir = self._ensure_temp_audio_dir()
        timestamp = int(time.time())
        random_suffix = random.randint(1000, 9999)  # ç°åœ¨randomå·²å¯¼å…¥
        temp_file = os.path.join(temp_audio_dir, f"command_{timestamp}_{random_suffix}.wav")
        return temp_file

    def cleanup_temp_files(self, max_age_seconds=3600):
        """æ¸…ç†è¿‡æœŸçš„ä¸´æ—¶æ–‡ä»¶"""
        try:
            temp_audio_dir = self._ensure_temp_audio_dir()
            current_time = time.time()
            deleted_count = 0

            for filename in os.listdir(temp_audio_dir):
                file_path = os.path.join(temp_audio_dir, filename)
                if os.path.isfile(file_path) and filename.endswith('.wav'):
                    # æ£€æŸ¥æ–‡ä»¶å¹´é¾„
                    file_age = current_time - os.path.getctime(file_path)
                    if file_age > max_age_seconds:
                        try:
                            os.remove(file_path)
                            deleted_count += 1
                        except Exception as e:
                            print(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {filename}: {e}")

            if deleted_count > 0:
                print(f"âœ… å·²æ¸…ç† {deleted_count} ä¸ªè¿‡æœŸä¸´æ—¶æ–‡ä»¶")

        except Exception as e:
            print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def safe_calculate_volume(self, audio_data):
        """å®‰å…¨è®¡ç®—éŸ³é‡ï¼Œé¿å…æ— æ•ˆå€¼"""
        try:
            if audio_data is None or len(audio_data) == 0:
                return 0
            # ç¡®ä¿æ•°æ®æ˜¯æœ‰æ•ˆçš„
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            if len(audio_array) == 0:
                return 0
            # è®¡ç®—RMSéŸ³é‡
            squared = np.square(audio_array.astype(np.float64))
            mean_squared = np.mean(squared)
            if mean_squared <= 0:
                return 0
            rms = np.sqrt(mean_squared)
            return rms
        except Exception as e:
            return 0

    def _check_audio_quality(self, frames):
        """æ£€æŸ¥éŸ³é¢‘æ•°æ®è´¨é‡"""
        try:
            if not frames:
                return False, "æ— éŸ³é¢‘æ•°æ®"

            # åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ•°æ®
            audio_data = b''.join(frames)
            if len(audio_data) < 16000:  # è‡³å°‘1ç§’çš„éŸ³é¢‘
                return False, f"éŸ³é¢‘æ•°æ®è¿‡çŸ­: {len(audio_data)} bytes"

            # è½¬æ¢ä¸ºnumpyæ•°ç»„åˆ†æ
            audio_array = np.frombuffer(audio_data, dtype=np.int16)

            # æ£€æŸ¥éŸ³é‡
            rms = np.sqrt(np.mean(np.square(audio_array.astype(np.float64))))
            if rms < 100:
                return False, f"éŸ³é¢‘éŸ³é‡è¿‡ä½: RMS={rms:.1f}"

            # æ£€æŸ¥æ˜¯å¦ä¸ºé™éŸ³ï¼ˆæ‰€æœ‰å€¼æ¥è¿‘0ï¼‰
            if np.max(np.abs(audio_array)) < 1000:
                return False, f"å¯èƒ½ä¸ºé™éŸ³: å³°å€¼={np.max(np.abs(audio_array))}"

            return True, f"éŸ³é¢‘è´¨é‡æ­£å¸¸: é•¿åº¦={len(audio_array)} samples, RMS={rms:.1f}"

        except Exception as e:
            return False, f"éŸ³é¢‘è´¨é‡æ£€æŸ¥å¤±è´¥: {e}"

    def record_until_silence(self, output_file=None):
        """å½•éŸ³æ–¹æ³• - å¢å¼ºç‰ˆæœ¬ï¼šæ”¹è¿›æ’­æ”¾çŠ¶æ€æ£€æŸ¥"""
        # å¢å¼ºçš„æ’­æ”¾çŠ¶æ€æ£€æŸ¥
        if self.should_ignore_for_playback():
            self.logger.debug("è·³è¿‡å½•éŸ³ï¼šæ­£åœ¨æ’­æ”¾è¯­éŸ³æˆ–å†·å´æœŸå†…")
            return None

        if self._is_cleaning_up or not self.recognizer:
            return None

        # ä¿å­˜å”¤é†’è¯çŠ¶æ€
        is_after_wake_word = self.wake_word_detected

        if is_after_wake_word:
            silence_threshold = 1.2
            silence_duration = 2.0
            min_recording_time = 3.0
        else:
            silence_threshold = self.silence_threshold
            silence_duration = self.silence_duration
            min_recording_time = 0

        try:
            # åˆ›å»ºæ–°çš„è¯†åˆ«å™¨å®ä¾‹
            self.recognizer = vosk.KaldiRecognizer(self.model, self.rate)

            stream = self.audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )

            if is_after_wake_word:
                print("ğŸ¤ å”¤é†’è¯å·²è¯†åˆ«ï¼Œç°åœ¨å¯ä»¥å¼€å§‹è¯´è¯...")
            else:
                print("ğŸ¤ ç°åœ¨å¯ä»¥å¼€å§‹è¯´è¯...")

            frames = []
            silent_chunks = 0
            voice_chunks = 0
            recognized_text = ""
            last_voice_time = time.time()
            recording_start = time.time()
            min_recording_end = recording_start + min_recording_time

            # å½•éŸ³å¾ªç¯ - å¢å¼ºæ’­æ”¾çŠ¶æ€æ£€æŸ¥
            while True:
                if self._is_cleaning_up:
                    break

                # å…³é”®ï¼šå¢å¼ºçš„æ’­æ”¾çŠ¶æ€æ£€æŸ¥
                if self.should_ignore_for_playback():
                    self.logger.debug("å½•éŸ³ä¸­æ–­ï¼šæ£€æµ‹åˆ°è¯­éŸ³æ’­æ”¾æˆ–å†·å´æœŸ")
                    break

                data = stream.read(self.chunk, exception_on_overflow=False)
                if not data:
                    continue

                # ç®€å•çš„ç³»ç»Ÿå£°éŸ³æ£€æµ‹ï¼Œåªè¿‡æ»¤æ˜æ˜¾çš„ç³»ç»Ÿæ’­æ”¾å£°éŸ³
                if self.is_system_playback_audio(data):
                    continue

                frames.append(data)

                volume = self.safe_calculate_volume(data)

                current_time = time.time()
                is_min_recording_period = current_time < min_recording_end

                if volume > silence_threshold or (is_after_wake_word and is_min_recording_period):
                    silent_chunks = 0
                    last_voice_time = current_time
                    voice_chunks += 1

                    if self.recognizer.AcceptWaveform(data):
                        result = json.loads(self.recognizer.Result())
                        text = result.get('text', '').strip()
                        if text:
                            recognized_text = text
                            if is_after_wake_word and len(recognized_text) > 1 and not self._is_wake_word_only(recognized_text):
                                break
                else:
                    silent_chunks += 1

                # åœæ­¢æ¡ä»¶
                current_time = time.time()
                elapsed_time = current_time - recording_start

                if is_min_recording_period:
                    continue

                if current_time - last_voice_time > silence_duration:
                    break

                if elapsed_time > 6.0:
                    break

            # åœæ­¢æµ
            stream.stop_stream()
            stream.close()

            # å¦‚æœå› ä¸ºæ’­æ”¾çŠ¶æ€è€Œä¸­æ–­å½•éŸ³ï¼Œç›´æ¥è¿”å›None
            if self.should_ignore_for_playback():
                self.logger.debug("å½•éŸ³å› æ’­æ”¾çŠ¶æ€ä¸­æ–­ï¼Œä¿æŒå”¤é†’çŠ¶æ€")
                return None

            # è·å–æœ€ç»ˆç»“æœ
            try:
                if frames:
                    remaining_data = b''.join(frames)
                    if self.recognizer.AcceptWaveform(remaining_data):
                        result = json.loads(self.recognizer.Result())
                        final_text = result.get('text', '').strip()
                        if final_text:
                            recognized_text = final_text

                    if not recognized_text:
                        partial_result = json.loads(self.recognizer.PartialResult())
                        partial_text = partial_result.get('partial', '').strip()
                        if partial_text:
                            recognized_text = partial_text
            except Exception as e:
                print(f"âŒ æœ€ç»ˆç»“æœå¤„ç†å¤±è´¥: {e}")

            # å¤„ç†ç»“æœ
            total_time = time.time() - recording_start

            if recognized_text and recognized_text.strip():
                cleaned_text = self.clean_transcription(recognized_text)

                # æ£€æŸ¥æ— æ•ˆç»“æœ
                invalid_results = ['æ£€æµ‹åˆ°è¯­éŸ³ä½†æœªèƒ½è¯†åˆ«', 'è¯­éŸ³è¯†åˆ«å¤±è´¥', 'è¯­éŸ³è¯†åˆ«å¼‚å¸¸']
                if any(invalid in cleaned_text for invalid in invalid_results):
                    if is_after_wake_word:
                        self.wake_word_detected = False
                    return None

                if is_after_wake_word:
                    self.wake_word_detected = False

                print(f"ğŸ‰ å½•éŸ³å®Œæˆ: '{cleaned_text}' (è€—æ—¶: {total_time:.1f}s)")
                return cleaned_text
            elif voice_chunks > 1:
                if is_after_wake_word:
                    self.wake_word_detected = False
                return "æ£€æµ‹åˆ°è¯­éŸ³ä½†æœªèƒ½è¯†åˆ«"
            else:
                if is_after_wake_word:
                    self.wake_word_detected = False
                return None

        except Exception as e:
            print(f"âŒ å½•éŸ³è¯†åˆ«å¤±è´¥: {e}")
            if is_after_wake_word:
                self.wake_word_detected = False
            try:
                stream.stop_stream()
                stream.close()
            except:
                pass
            return None

    def _is_likely_system_sound_by_features(self, audio_data):
        """é€šè¿‡éŸ³é¢‘ç‰¹å¾æ£€æµ‹æ˜¯å¦ä¸ºç³»ç»Ÿå£°éŸ³ - æ–°å¢æ–¹æ³•"""
        try:
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            if len(audio_array) < 100:
                return False

            # è®¡ç®—éŸ³é¢‘ç‰¹å¾
            rms = np.sqrt(np.mean(np.square(audio_array.astype(np.float64))))
            peak = np.max(np.abs(audio_array))

            # è®¡ç®—é¢‘è°±å¹³å¦åº¦
            fft_data = np.abs(np.fft.fft(audio_array))
            fft_data = fft_data[:len(fft_data)//2]
            spectral_flatness = np.exp(np.mean(np.log(fft_data + 1e-10))) / (np.mean(fft_data) + 1e-10)

            # ç³»ç»Ÿå£°éŸ³çš„ç‰¹å¾ï¼šä¸­ç­‰éŸ³é‡ã€å¹³ç¨³é¢‘è°±ã€ç‰¹å®šé¢‘ç‡èŒƒå›´
            is_system_sound = (
                # éŸ³é‡èŒƒå›´ï¼ˆé¿å…ç¯å¢ƒå™ªéŸ³å’Œè¿‡å¤§å£°éŸ³ï¼‰
                    500 < rms < 12000 and
                    # å³°å€¼é™åˆ¶
                    peak < 20000 and
                    # é¢‘è°±å¹³å¦åº¦ï¼ˆç³»ç»Ÿå£°éŸ³é€šå¸¸é¢‘è°±è¾ƒå¹³å¦ï¼‰
                    spectral_flatness > 0.1 and spectral_flatness < 0.8
            )

            return is_system_sound

        except Exception as e:
            return False

    def _is_wake_word_only(self, text):
        """åˆ¤æ–­æ˜¯å¦ä¸ºçº¯å”¤é†’è¯ï¼ˆæ²¡æœ‰å®é™…å‘½ä»¤ï¼‰"""
        wake_word_patterns = [
            r'^å°æ™º$',
            r'^ä½ å¥½å°æ™º$',
            r'^å°æ™ºä½ å¥½$',
            r'^ä½ å¥½$',
            r'^æ‚¨å¥½$'
        ]

        for pattern in wake_word_patterns:
            if re.match(pattern, text.strip()):
                return True
        return False

    def _save_audio_file(self, frames, output_file):
        """ä¿å­˜éŸ³é¢‘æ–‡ä»¶ - ä½¿ç”¨é¡¹ç›®temp_audioç›®å½•"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(output_file)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)

            wf = wave.open(output_file, 'wb')
            wf.setnchannels(self.channels)
            wf.setsampwidth(self.audio.get_sample_size(self.format))
            wf.setframerate(self.rate)
            wf.writeframes(b''.join(frames))
            wf.close()
            return True
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å½•éŸ³æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def transcribe_audio(self, audio_file_path, delete_after_transcribe=True):
        """è½¬å½•éŸ³é¢‘æ–‡ä»¶ - æ·»åŠ è‡ªåŠ¨æ¸…ç†é€‰é¡¹"""
        if self._is_cleaning_up:
            return None

        try:
            if not self.recognizer:
                print("âŒ Vosk è¯†åˆ«å™¨æœªåˆå§‹åŒ–")
                return None

            if not os.path.exists(audio_file_path):
                print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file_path}")
                return None

            wf = wave.open(audio_file_path, 'rb')

            # æ£€æŸ¥éŸ³é¢‘æ ¼å¼
            if wf.getnchannels() != 1:
                print("âŒ åªæ”¯æŒå•å£°é“éŸ³é¢‘")
                wf.close()
                return None

            # åˆ›å»ºæ–°çš„è¯†åˆ«å™¨
            self.recognizer = vosk.KaldiRecognizer(self.model, wf.getframerate())

            results = []
            while True:
                data = wf.readframes(4000)
                if len(data) == 0:
                    break

                if self.recognizer.AcceptWaveform(data):
                    result = json.loads(self.recognizer.Result())
                    text = result.get('text', '').strip()
                    if text:
                        results.append(text)

            # è·å–æœ€ç»ˆç»“æœ
            final_result = json.loads(self.recognizer.FinalResult())
            final_text = final_result.get('text', '').strip()
            if final_text:
                results.append(final_text)

            wf.close()

            # è½¬å½•å®Œæˆååˆ é™¤æ–‡ä»¶
            if delete_after_transcribe:
                try:
                    os.remove(audio_file_path)
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

            transcription = ' '.join(results).strip()
            if transcription:
                cleaned_transcription = self.clean_transcription(transcription)
                print(f"âœ… è½¬å½•å®Œæˆ: '{cleaned_transcription}'")
                return cleaned_transcription
            else:
                return None

        except Exception as e:
            print(f"âŒ è½¬å½•å¤±è´¥: {e}")
            # å³ä½¿å¤±è´¥ä¹Ÿå°è¯•åˆ é™¤æ–‡ä»¶
            if delete_after_transcribe and os.path.exists(audio_file_path):
                try:
                    os.remove(audio_file_path)
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
            return None

    def clean_transcription(self, text):
        """è¯­éŸ³è¯†åˆ«æ–‡æœ¬æ¸…æ´— - ç»Ÿä¸€æ¸…æ´—é€»è¾‘ï¼Œé¿å…é‡å¤æ¸…æ´—"""
        if not text:
            return ""

        original_text = text

        # ç¬¬ä¸€æ­¥ï¼šç§»é™¤æ‰€æœ‰ç©ºæ ¼
        text = re.sub(r'\s+', '', text)

        # ç¬¬äºŒæ­¥ï¼šåŸºç¡€è¯­éŸ³è¯†åˆ«é”™è¯¯çº æ­£ï¼ˆè®¾å¤‡æ§åˆ¶ç›¸å…³ï¼‰
        basic_corrections = {
            'å°åª': 'å°æ™º', 'å°çŸ¥': 'å°æ™º', 'å°ä¹‹': 'å°æ™º', 'å°å¿—': 'å°æ™º',
            'å°æ™ºå°æ™º': 'å°æ™º',
            'ç›¸å­': 'æŸœå­', 'ç®±å­': 'æŸœå­', 'è´µå­': 'æŸœå­', 'æŸœäº†': 'æŸœå­', 'é¬¼å­': 'æŸœå­',  # æ–°å¢"é¬¼å­"çš„çº æ­£
            'å…³æ¯•': 'å…³é—­', 'å®Œæ¯•': 'å…³é—­',
            'ç±»': 'åˆ—', 'å·': 'åˆ—', 'ä¸ª': 'åˆ—'
        }

        for wrong, correct in basic_corrections.items():
            if wrong in text:
                text = text.replace(wrong, correct)

        # ç¬¬ä¸‰æ­¥ï¼šç‰¹å®šçŸ­è¯­çš„çº æ­£ï¼ˆæ–°å¢ï¼‰
        phrase_corrections = {
            'å…³é—­é¬¼å­': 'å…³é—­æŸœå­',
            'æ‰“å¼€é¬¼å­': 'æ‰“å¼€æŸœå­',
            'é¬¼å­å…³é—­': 'æŸœå­å…³é—­',
            'é¬¼å­æ‰“å¼€': 'æŸœå­æ‰“å¼€'
        }

        for wrong_phrase, correct_phrase in phrase_corrections.items():
            if wrong_phrase in text:
                text = text.replace(wrong_phrase, correct_phrase)

        return text

    def listen_for_wake_word(self, timeout=8):
        """ç›‘å¬å”¤é†’è¯ - ä¿®å¤ç‰ˆæœ¬ï¼šå¢å¼ºå”¤é†’è¯æ£€æµ‹å’Œæ’­æ”¾çŠ¶æ€æ£€æŸ¥"""
        # åœ¨å¼€å§‹æ—¶æ£€æŸ¥æ’­æ”¾çŠ¶æ€
        if self.should_ignore_for_playback():
            return False

        if self._is_cleaning_up:
            return False

        try:
            # é‡ç½®å”¤é†’è¯çŠ¶æ€
            self.wake_word_detected = False

            # ä½¿ç”¨æ›´çµæ•çš„å½•éŸ³å‚æ•°
            original_threshold = self.silence_threshold
            original_duration = self.silence_duration

            # ä¸´æ—¶è°ƒæ•´å‚æ•°ï¼Œæé«˜å”¤é†’è¯æ£€æµ‹çµæ•åº¦
            self.silence_threshold = max(1.0, self.ambient_noise_level * 1.5)  # é™ä½é˜ˆå€¼
            self.silence_duration = 1.5  # ç¼©çŸ­é™éŸ³æ£€æµ‹æ—¶é—´

            # ç›´æ¥å½•éŸ³è¯†åˆ«
            transcription = self.record_until_silence()

            # æ¢å¤åŸå§‹å‚æ•°
            self.silence_threshold = original_threshold
            self.silence_duration = original_duration

            if transcription:
                # å¢å¼ºå”¤é†’è¯æ£€æµ‹
                wake_detected = self._enhanced_wake_word_detection(transcription)

                if wake_detected:
                    self.wake_word_detected = True
                    print(f"âœ… å”¤é†’è¯ '{self.wake_word}' æ£€æµ‹æˆåŠŸ!")
                    return True

            return False

        except Exception as e:
            print(f"âŒ å”¤é†’è¯æ£€æµ‹å¤±è´¥: {e}")
            # ç¡®ä¿å¼‚å¸¸æ—¶æ¢å¤å‚æ•°
            if 'original_threshold' in locals():
                self.silence_threshold = original_threshold
                self.silence_duration = original_duration
            return False

    def _enhanced_wake_word_detection(self, text):
        """å¢å¼ºçš„å”¤é†’è¯æ£€æµ‹ - ä¿®å¤ç‰ˆæœ¬ï¼šè¿‡æ»¤æ— æ•ˆè¯†åˆ«ç»“æœ"""
        if not text:
            return False

        # ç§»é™¤ç©ºæ ¼
        cleaned_text = re.sub(r'\s+', '', text)

        # é¦–å…ˆï¼šè¿‡æ»¤æ‰æ— æ•ˆçš„è¯†åˆ«ç»“æœ
        invalid_patterns = [
            'æ£€æµ‹åˆ°è¯­éŸ³ä½†æœªèƒ½è¯†åˆ«',
            'è¯­éŸ³è¯†åˆ«å¤±è´¥',
            'æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³',
            'è¯­éŸ³è¯†åˆ«å¼‚å¸¸'
        ]

        for invalid in invalid_patterns:
            if invalid in cleaned_text:
                return False

        # å”¤é†’å…³é”®è¯åˆ—è¡¨
        wake_keywords = [
            'å°æ™º', 'å°çŸ¥', 'å°ä¹‹', 'å°å¿—', 'å°åª',
            'ä½ å¥½', 'æ‚¨å¥½', 'å—¨', 'å˜¿'
        ]

        # 1. ç›´æ¥æ£€æŸ¥æ˜¯å¦åŒ…å«ä»»ä½•å”¤é†’å…³é”®è¯
        for keyword in wake_keywords:
            if keyword in cleaned_text:
                return True

        # 2. æ£€æŸ¥çŸ­æ–‡æœ¬ï¼ˆé•¿åº¦å°äºç­‰äº6ä¸ªå­—ç¬¦ï¼‰ä¸”å¿…é¡»åŒ…å«æœ‰æ•ˆå…³é”®è¯
        if len(cleaned_text) <= 6:
            # çŸ­æ–‡æœ¬å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆçš„ä¸­æ–‡å­—ç¬¦æˆ–å…³é”®è¯
            has_valid_content = any(
                char in cleaned_text for char in ['å°', 'ä½ ', 'æ‚¨', 'å—¨', 'å˜¿']
            )
            if has_valid_content:
                return True
            else:
                return False

        # 3. æ£€æŸ¥æ˜¯å¦ä»¥é—®å€™å¼€å¤´
        greeting_starts = ['ä½ å¥½', 'æ‚¨å¥½', 'å—¨', 'å˜¿']
        for greeting in greeting_starts:
            if cleaned_text.startswith(greeting):
                return True

        # 4. æ£€æŸ¥æ˜¯å¦åŒ…å«"å°"å­—ä¸”é•¿åº¦é€‚ä¸­
        if 'å°' in cleaned_text and len(cleaned_text) <= 8:
            # ç¡®ä¿ä¸æ˜¯çº¯æ— æ•ˆå†…å®¹
            if not any(invalid in cleaned_text for invalid in invalid_patterns):
                return True

        return False

    def calibrate_microphone(self):
        """æ ¡å‡†éº¦å…‹é£ - å¯é€‰æ‰§è¡Œï¼Œé¿å…è¿‡åº¦æ ¡å‡†"""
        if self._is_cleaning_up:
            return

        # å¦‚æœä¸æ˜¯å¼ºåˆ¶æ ¡å‡†ï¼Œä¸”å·²ç»æœ‰åˆç†çš„é˜ˆå€¼ï¼Œè·³è¿‡
        if 1.5 <= self.silence_threshold <= 4.0:
            return

        try:
            stream = self.audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )

            noise_levels = []
            for i in range(30):  # å‡å°‘é‡‡æ ·æ¬¡æ•°
                if self._is_cleaning_up:
                    break
                data = stream.read(self.chunk, exception_on_overflow=False)
                if data:
                    volume = self.safe_calculate_volume(data)
                    noise_levels.append(volume)
                time.sleep(0.05)

            stream.stop_stream()
            stream.close()

            if noise_levels:
                # ä½¿ç”¨æ›´ä¿å®ˆçš„è®¡ç®—
                median_noise = np.median(noise_levels)
                noise_75th = np.percentile(noise_levels, 75)

                # è®¾ç½®åˆç†çš„é˜ˆå€¼èŒƒå›´
                base_threshold = max(median_noise * 1.8, 2.0)  # æœ€ä½2.0
                self.silence_threshold = min(base_threshold, 4.5)  # æœ€é«˜4.5
                self.ambient_noise_level = median_noise

            else:
                # ä¿å®ˆçš„é»˜è®¤å€¼
                self.silence_threshold = 3.0

        except Exception as e:
            print(f"âŒ éº¦å…‹é£æ ¡å‡†å¤±è´¥: {e}")
            self.silence_threshold = 3.0  # ä¿å®ˆé»˜è®¤å€¼

    def record_and_transcribe(self, command_handler=None, require_wake_word=False):
        """å½•éŸ³å¹¶è½¬æ–‡å­— - å¢å¼ºæ’­æ”¾çŠ¶æ€æ£€æŸ¥"""
        # æ£€æŸ¥æ’­æ”¾çŠ¶æ€
        if self.should_ignore_for_playback():
            return None

        try:
            # å¦‚æœä¸éœ€è¦å”¤é†’è¯ï¼Œç›´æ¥å½•éŸ³
            if not require_wake_word:
                text = self.record_until_silence()
                if text and text != "æ£€æµ‹åˆ°è¯­éŸ³ä½†æœªèƒ½è¯†åˆ«":
                    # ç´§æ€¥ä¿®å¤ï¼šç«‹å³æ£€æŸ¥æ˜¯å¦ä¸ºå”¤é†’è¯
                    if command_handler and command_handler._is_pure_wakeup_call(text):
                        return text
                    return text
                elif text == "æ£€æµ‹åˆ°è¯­éŸ³ä½†æœªèƒ½è¯†åˆ«":
                    return "è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•"
                else:
                    return None

            # å¦‚æœéœ€è¦å”¤é†’è¯ï¼Œå…ˆæ£€æµ‹å”¤é†’è¯
            else:
                wake_detected = self.listen_for_wake_word()
                if wake_detected:
                    text = self.record_until_silence()
                    if text and text != "æ£€æµ‹åˆ°è¯­éŸ³ä½†æœªèƒ½è¯†åˆ«":
                        return text
                    elif text == "æ£€æµ‹åˆ°è¯­éŸ³ä½†æœªèƒ½è¯†åˆ«":
                        return "è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•"
                    else:
                        return None
                else:
                    return None

        except Exception as e:
            print(f"âŒ å½•éŸ³è¿‡ç¨‹é”™è¯¯: {e}")
            return "è¯­éŸ³è¯†åˆ«å¼‚å¸¸ï¼Œè¯·é‡è¯•"

    def detect_ambient_noise(self, duration=3):
        """å¢å¼ºçš„ç¯å¢ƒå™ªéŸ³æ£€æµ‹"""
        try:
            stream = self.audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )

            noise_levels = []
            for i in range(int(duration * self.rate / self.chunk)):
                data = stream.read(self.chunk, exception_on_overflow=False)
                volume = self.safe_calculate_volume(data)
                noise_levels.append(volume)

            stream.stop_stream()
            stream.close()

            if noise_levels:
                # ä½¿ç”¨æ›´ç²¾ç¡®çš„ç»Ÿè®¡æ–¹æ³•
                median_noise = np.median(noise_levels)
                noise_75th = np.percentile(noise_levels, 75)

                # åŠ¨æ€è®¾ç½®é˜ˆå€¼ï¼šä½¿ç”¨ä¸­ä½æ•° + è¾ƒå°çš„å®‰å…¨ä½™é‡
                base_threshold = max(1.0, median_noise * 1.2)  # æœ€ä½1.0ï¼Œè¾ƒå°çš„ä¹˜æ•°
                self.silence_threshold = min(base_threshold, 3.0)  # æœ€é«˜3.0
                self.ambient_noise_level = median_noise

                return True
            return False

        except Exception as e:
            print(f"âŒ ç¯å¢ƒå™ªéŸ³æ£€æµ‹å¤±è´¥: {e}")
            # è®¾ç½®ä¿å®ˆçš„é»˜è®¤å€¼
            self.silence_threshold = 2.0
            return False

    def set_playback_status(self, is_playing):
        """è®¾ç½®æ’­æ”¾çŠ¶æ€ - å…¼å®¹æ€§æ–¹æ³•ï¼Œè°ƒç”¨set_speaking_status"""
        self.set_speaking_status(is_playing)

    def cleanup(self):
        """å®‰å…¨æ¸…ç†èµ„æº - åŒ…æ‹¬ä¸´æ—¶æ–‡ä»¶å’Œç›‘å¬å™¨"""
        if self._is_cleaning_up:
            return

        try:
            self._is_cleaning_up = True

            # æ¸…ç†ç›‘å¬å™¨
            self._playback_state_listeners.clear()

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self.cleanup_temp_files(max_age_seconds=0)  # åˆ é™¤æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶

            if hasattr(self, 'audio') and self.audio:
                self.audio.terminate()
            if hasattr(self, 'model') and self.model:
                self.model = None
                self.recognizer = None
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†è¯­éŸ³è¯†åˆ«å™¨æ—¶å‡ºç°è­¦å‘Š: {e}")